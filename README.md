========================================================================

# Zero-shot Emotion Classification via Reinforced Self-training

========================================================================

![image](https://user-images.githubusercontent.com/26008298/132282618-0440b99c-af47-4e75-9c45-2253ba94f59d.png)

========================================================================

| author | mizukiyuta | <br />   
| department | Tokyo Metropolitan University System Design |  <br />

========================================================================

## Used device

### VIVE PRO EYE headset(for eye tracking)

### Polar H10(for ECG)

## Data Collection
Based on VR virtual world to arose people's emotion by group discussion/communication<br /> 
meanwhile,sensors(headset,Polar H10) will collect collaborators' bio-data and save to csv 

## Experiment Design
#### APP: VRChat
Participants: more than 20 groups of collaborators (3 people a group)
#### Used Raw Data: 
ECG，Audio，Eye Tracking，Lip Tracking，Head position&rotation

#### Details:	
One participant wear sensors and VR headset as a main talker
other two participants just wear VR headset and talk
Each conversation lasted approximately three minutes
#### Topics:
Talk about specific topics that are likely to cause emotional fluctuations or produce opposing positions
