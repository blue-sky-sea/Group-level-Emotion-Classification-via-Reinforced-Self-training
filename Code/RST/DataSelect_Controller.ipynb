{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNgs0lKvZv0o03RUsJrht3y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFvTMCCaEU7_","executionInfo":{"status":"ok","timestamp":1663042759300,"user_tz":-540,"elapsed":30872,"user":{"displayName":"yi liu","userId":"07321536629726095967"}},"outputId":"2b731e03-56b6-4936-d60e-23cf5ab1e054"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Data manipulation\n","import pandas as pd\n","\n","# Visualization\n","import plotly.express as px\n","\n","# Sklearn\n","from sklearn.model_selection import train_test_split # for splitting data into train and test samples\n","from sklearn.svm import SVC # for Support Vector Classification baseline model\n","from sklearn.semi_supervised import SelfTrainingClassifier # for Semi-Supervised learning\n","from sklearn.metrics import classification_report # for model evaluation metrics\n","from sklearn.metrics import f1_score\n","\n","from sklearn.utils import shuffle\n","import math\n","import os\n","import numpy as np\n","\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","import keras.backend as K\n","\n","import time\n","import datetime\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Read in data\n","FOLDER = \"/content/drive/MyDrive/Emotion-RST/marketing_campaign.csv\"\n","df = pd.read_csv(FOLDER, \n","                 encoding='utf-8', delimiter=';',\n","                 usecols=['ID', 'Year_Birth', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome', 'MntWines', 'MntMeatProducts'])\n","# Create a flag to denote whether the person has any dependants at home (either kids or teens)\n","df['Dependents_Flag']=df.apply(lambda x: 1 if x['Kidhome']+x['Teenhome']>0 else 0, axis=1)\n","\n","# Print datafram"],"metadata":{"id":"myHv40oAEtVV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#将训练集划分为子训练集、验证集，比例是0.75:0.25\n","df_train, df_test = train_test_split(df, test_size=0.25, random_state=0)\n","print('Size of train dataframe: ', df_train.shape[0])\n","print('Size of test dataframe: ', df_test.shape[0])\n","print(\"#\"*50)\n","\n","#现在让我们屏蔽训练数据中 95% 的标签，并创建一个使用“-1”表示未标记（屏蔽）数据的目标变量：\n","# Create a flag for label masking\n","df_train['Random_Mask'] = True\n","df_train.loc[df_train.sample(frac=0.05, random_state=0).index, 'Random_Mask'] = False\n","# Create a new target colum with labels. The 1's and 0's are original labels and -1 represents unlabeled (masked) data\n","df_train['Dependents_Target']=df_train.apply(lambda x: x['Dependents_Flag'] if x['Random_Mask']==False else -1, axis=1)\n","# Show target value distribution\n","print('Target Value Distribution:')\n","print(df_train['Dependents_Target'].value_counts())\n","\n","#创建Ds,Du,Ds_dev\n","Ds = df_train[df_train['Dependents_Target']!=-1] #labeled training data in masked Dataset\n","Du = df_train[df_train['Dependents_Target']==-1] #unlabeled training data in masked Dataset\n","Ds_dev = df_test\n","\n","print(\"#\"*50)\n","print('Size of labeled seen data Ds dataframe: ', Ds.shape[0])\n","print('Size of unlabeled unseen data Du dataframe: ', Du.shape[0])\n","print('Size of seen validation set Ds_dev dataframe: ', Ds_dev.shape[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyqLhKVkExJZ","executionInfo":{"status":"ok","timestamp":1663042796824,"user_tz":-540,"elapsed":435,"user":{"displayName":"yi liu","userId":"07321536629726095967"}},"outputId":"2101864a-50e2-42f9-d1ce-af5972fa0ed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of train dataframe:  1680\n","Size of test dataframe:  560\n","##################################################\n","Target Value Distribution:\n","-1    1596\n"," 1      58\n"," 0      26\n","Name: Dependents_Target, dtype: int64\n","##################################################\n","Size of labeled seen data Ds dataframe:  84\n","Size of unlabeled unseen data Du dataframe:  1596\n","Size of seen validation set Ds_dev dataframe:  560\n"]}]},{"cell_type":"code","source":["def build_model():\n","    \"\"\"basic model.\n","    \"\"\"\n","    inputs = Input(shape=(4,), name='ob_input')\n","    x = Dense(16, activation='relu')(inputs)\n","    x = Dense(16, activation='relu')(x)\n","    x = Dense(1, activation='sigmoid')(x)\n","    model = Model(inputs=inputs, outputs=x)\n","    return model\n","\n","def calloss(y_true, y_pred):\n","      \"\"\"loss function.\n","      Arguments:\n","          y_true: (action, reward)\n","          y_pred: action_prob\n","\n","      Returns:\n","          loss: reward loss\n","      \"\"\"\n","      action_pred = y_pred\n","      action_true, discount_episode_reward = y_true[:, 0], y_true[:, 1]\n","\n","      action_true = K.reshape(action_true, (-1, 1))\n","      loss = K.binary_crossentropy(action_true, action_pred)\n","      loss = loss * K.flatten(discount_episode_reward)\n","\n","      return loss\n","\n","gamma = 0.75    \n","def discount_reward(rewards):\n","      \"\"\"Discount reward\n","      Arguments:\n","          rewards: rewards in a episode.\n","      \"\"\"\n","      # compute the discounted reward backwards through time.\n","      discount_rewards = np.zeros_like(rewards, dtype=np.float32)\n","      cumulative = 0.\n","      for i in reversed(range(len(rewards))):\n","          cumulative = cumulative * gamma + rewards[i]\n","          discount_rewards[i] = cumulative\n","\n","      # size the rewards to be unit normal (helps control the gradient estimator variance).\n","      discount_rewards -= np.mean(discount_rewards)\n","      discount_rewards //= np.std(discount_rewards)\n","\n","      discount_rewards = discount_rewards+1\n","      return list(discount_rewards)\n","\n","def getnewBpk(Bk,probs):\n","  Bpk = Bk.copy()\n","  actions = []\n","  for i in range(len(probs)):\n","    prob = probs[i][0]\n","    action = np.random.choice(np.array(range(2)), size=1, p=[1 - prob, prob])[0]\n","    actions.append(action)\n","  Bpk['action'] = actions\n","  Bpk = Bpk[Bpk['action']!=0]\n","  return Bpk,actions"],"metadata":{"id":"Y8fEfk14MayA","executionInfo":{"status":"ok","timestamp":1663044796687,"user_tz":-540,"elapsed":659,"user":{"displayName":"yi liu","userId":"07321536629726095967"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["svc_model = SVC(kernel='rbf', \n","    probability=True, \n","    C=1.0, # default = 1.0\n","    gamma='scale', # default = 'scale'\n","    random_state=0\n",")\n","\n","policy_model = build_model()\n","policy_model.compile(loss=calloss, optimizer=Adam(lr=0.01))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fxy3IVA6Mg5f","executionInfo":{"status":"ok","timestamp":1663044820479,"user_tz":-540,"elapsed":1093,"user":{"displayName":"yi liu","userId":"07321536629726095967"}},"outputId":"c5bef4ac-06ab-4fd2-c479-c90382c432a7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["class DataSelectController:\n","    def __init__(self,df_train,df_test):\n","        self.df_train = df_train #\n","        self.df_test = df_test #\n","\n","        self.labeled_train_dataset = df_train[df_train['Dependents_Target']!=-1] #\n","        self.unlabeled_train_dataset = df_train[df_train['Dependents_Target']==-1] #unlabeled training data in masked Dataset\n","        \n","        self.validation_dataset = df_test#\n","        self.unlabeled_validation_dataset = pd.DataFrame(columns=df_test.columns)\n","\n","        self.pseudo_labeled_dataset = pd.DataFrame(columns=self.labeled_train_dataset.columns)\n","        #self.pseudo_validation_dataset = pd.DataFrame(columns=self.labeled_train_dataset.columns)\n","\n","        self.base_svc_model = self.train_svc_model()\n","        self.policy_model = build_model()\n","        self.policy_model.compile(loss=calloss, optimizer=Adam(lr=0.01))\n","        pass\n","\n","    #inital environment\n","    def reset(self):\n","        self.labeled_train_dataset = self.df_train[df_train['Dependents_Target']!=-1] #\n","        self.unlabeled_train_dataset = self.df_train[df_train['Dependents_Target']==-1] #unlabeled training data in masked Dataset\n","        \n","        self.validation_dataset = self.df_test\n","        self.unlabeled_validation_dataset = pd.DataFrame(columns=self.df_test.columns)\n","\n","        self.pseudo_labeled_dataset = pd.DataFrame(columns=self.labeled_train_dataset.columns)\n","        #self.pseudo_validation_dataset = pd.DataFrame(columns=self.labeled_train_dataset.columns)\n","        self.base_svc_model = self.train_svc_model()\n","        pass\n","\n","    #update environment,每一个episode，更新一次pseudo_labeled_dataset，pseudo_validation_dataset，unlabeled_train_dataset\n","    def render(self):                     \n","        pass\n","\n","    #Train svc_model using trainset\n","    def train_svc_model_xy(self,trainset_x,trainset_y):\n","        clf = svc_model.fit(trainset_x,trainset_y)\n","        self.base_svc_model = clf\n","        return clf\n","    \n","    def train_svc_model(self):\n","        D_train_ = self.labeled_train_dataset if self.pseudo_labeled_dataset.empty else pd.concat([self.labeled_train_dataset, self.pseudo_labeled_dataset])\n","        clf = svc_model.fit(D_train_[['MntMeatProducts', 'MntWines']], D_train_['Dependents_Flag'].values)\n","        self.base_svc_model = clf\n","        return clf\n","\n","    def predict_unlabeled_set(self, unlabeled_set):\n","        proba = self.base_svc_model.predict_proba(unlabeled_set[['MntMeatProducts', 'MntWines']])\n","        predicted_label = self.base_svc_model.predict(unlabeled_set[['MntMeatProducts', 'MntWines']])\n","\n","        U = unlabeled_set.copy()\n","        U['proba_A'] = [a[0] for a in proba]\n","        U['proba_B'] = [b[1] for b in proba]\n","        U['predicted_label'] = predicted_label\n","\n","        U_predicted = U\n","        return U_predicted\n","\n","    def rank_U(self,U_predicted):\n","        U_predicted['proba_max'] = U_predicted.loc[:,['proba_A','proba_B']].T.max()\n","        U_ranked = U_predicted.sort_values('proba_max',ascending = False)\n","        U_ranked = U_ranked.drop(columns=['proba_max'])\n","        return U_ranked\n","\n","\n","    def select_Batch_k_PolicyNetwrok(self,policy_model,Batch_k):\n","        Batch_k_judged = Batch_k.copy()\n","        data_ = Batch_k[['MntMeatProducts','MntWines','proba_A','proba_B']]\n","        data_ = (data_-data_.min())/(data_.max()-data_.min())\n","        confidences = policy_model.predict(data_)\n","        actions = []\n","        for i in range(len(confidences)):\n","            prob = confidences[i][0]\n","            action = np.random.choice(np.array(range(2)), size=1, p=[1 - prob, prob])[0]\n","            actions.append(action)\n","        Batch_k_judged['action'] = actions\n","        Batch_k_selected = Batch_k_judged.copy()\n","        Batch_k_selected = Batch_k_selected[Batch_k_selected['action']!=0]\n","        Batch_k_unselected = Batch_k_judged.copy()\n","        Batch_k_unselected = Batch_k_unselected[Batch_k_unselected['action']==0]\n","        return Batch_k_judged, Batch_k_selected, Batch_k_unselected, actions\n","\n","    def cal_f1(self,clf_,validation_set):\n","\n","        y_pred = clf_.predict(validation_set[['MntMeatProducts', 'MntWines']])\n","        #validation_score_list.append(clf_.score(validation_dataset[['MntMeatProducts', 'MntWines']], validation_dataset['Dependents_Flag'].values))\n","        validation_set_f1 = f1_score(validation_set['Dependents_Flag'].values, y_pred, average='macro')##TODO\n","\n","        return validation_set_f1\n","        pass\n","\n","    #对当前状态的Unlabeled_set按照Batch分组进行Policy Network评估，再合并计算各自的Reward\n","    def step(self,U, batch):\n","        observation = None\n","        done = False\n","        info = \"\"\n","\n","        U = shuffle(U)#打乱U\n","        every_epoch_num = math.floor((len(U)/batch))\n","\n","        Batch_k_list = []\n","        Batch_actions_list=[]\n","        Batch_k_judged_list = []\n","        validation_f1_list= []\n","        pseudo_f1_list = []\n","\n","        for k in range(batch):\n","            #get a batch Bk from U\n","            if k < (batch-1):\n","                Batch_k = U[every_epoch_num * k: every_epoch_num * (k + 1)]\n","            else:\n","                Batch_k = U[every_epoch_num * k:]\n","            \n","            Batch_k_judged, Batch_k_selected, Batch_k_unselected, actions = self.select_Batch_k_PolicyNetwrok(policy_model, Batch_k)\n","            Batch_k_list.append(Batch_k)\n","            Batch_actions_list.append(actions)\n","            Batch_k_judged_list.append(Batch_k_judged)\n","      \n","            #Train model clf' with Bpk\n","            clf_ = svc_model.fit(Batch_k_selected[['MntMeatProducts', 'MntWines']], Batch_k_selected['predicted_label'].values)\n","\n","            validation_f1 = self.cal_f1(clf_,self.validation_dataset)\n","            validation_f1_list.append(validation_f1)\n","            if(self.pseudo_labeled_dataset.empty!=True):\n","                pseudo_f1 = self.cal_f1(clf_,self.pseudo_labeled_dataset)\n","                pseudo_f1_list.append(pseudo_f1)\n","\n","        validation_f1_mean = np.mean(validation_f1_list)\n","        validation_f1_std = np.std(validation_f1_list)\n","\n","        pseudo_f1_mean = np.mean(pseudo_f1_list)\n","        pseudo_f1_std = np.std(pseudo_f1_list)\n","         \n","        for k in range(batch):\n","            reward1 = (validation_f1_list[k] - validation_f1_mean)/validation_f1_std\n","            reward2 = 0\n","            lamda =0\n","            if(self.pseudo_labeled_dataset.empty!=True):\n","              reward2 = (pseudo_f1_list[k] - pseudo_f1_mean)/pseudo_f1_std\n","              lamda =len(self.validation_dataset)/len(self.pseudo_labeled_dataset)\n","\n","            reward = reward1 + lamda*reward2\n","\n","            Batch_k = Batch_k_list[k]\n","            Batch_actions = Batch_actions_list[k]\n","            Batch_rewards = [reward]*len(Batch_actions)\n","            X = Batch_k[['MntMeatProducts', 'MntWines','proba_A','proba_B']]\n","            y = np.array(list(zip(Batch_actions, Batch_rewards)))\n","\n","            loss = policy_model.train_on_batch(X, y)\n","            print('Batch: {} | Batch reward: {} | loss: {:.3f}'.format( k, reward, loss))\n","\n","        #完成后，需要对各个临时数据存储进行更新\n","          #集合全部Batch_k_judged，根据'action'字段选出selected和unselected\n","          #将selected添加到self.pseudo_labeled_dataset\n","          #将selected从self.unlabeled_train_dataset中去除\n","        U_judged = pd.concat(Batch_k_judged_list)#集合全部Batch_k_judged，\n","        U_selected = U_judged[U_judged['action']==1]#根据'action'字段选出selected和unselected\n","        U_unselected = U_judged[U_judged['action']!=1]#根据'action'字段选出selected和unselected\n","\n","\n","        U_selected = U_selected.drop(['proba_A', 'proba_B','action'], axis=1)\n","        self.pseudo_labeled_dataset = U_selected if self.pseudo_labeled_dataset.empty else pd.concat([self.pseudo_labeled_dataset, U_selected])#dataframe 参数不同，有bug，TODO\n","        self.unlabeled_train_dataset = pd.concat([self.unlabeled_train_dataset, U_selected, U_selected]).drop_duplicates(keep=False)\n","\n","        return observation, reward, done, info\n","\n"],"metadata":{"id":"qSkogMhGE0Xr","executionInfo":{"status":"ok","timestamp":1663057301219,"user_tz":-540,"elapsed":546,"user":{"displayName":"yi liu","userId":"07321536629726095967"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["                                                                                                                                 "],"metadata":{"id":"zRgIlSiXVBh3","executionInfo":{"status":"ok","timestamp":1663051660903,"user_tz":-540,"elapsed":709,"user":{"displayName":"yi liu","userId":"07321536629726095967"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["iteration = 2\n","episode = 100 #5000\n","batch = 7\n","Controller = DataSelectController(df_train, df_test)    \n","\n","for i in range(iteration):\n","    Controller.reset()#恢复数据集，初始化临时数据存储\n","\n","    for i in range(episode):\n","        Controller.train_svc_model()#Step1：训练svc class matching model（合并labeled dataset和pseudo_labeled_dataset）\n","        U_predicted = Controller.predict_unlabeled_set(Controller.unlabeled_train_dataset)\n","        observation, reward, done, info = Controller.step(U_predicted, batch) #\n","        Controller.render()#更新临时数据存储\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3jnGaTQSmkKb","executionInfo":{"status":"error","timestamp":1663057333480,"user_tz":-540,"elapsed":29891,"user":{"displayName":"yi liu","userId":"07321536629726095967"}},"outputId":"592e3299-ccb8-4cd9-8713-48741d37cdd6"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  keepdims=keepdims, where=where)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n","  subok=False)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]},{"output_type":"stream","name":"stdout","text":["Batch: 0 | Batch reward: -1.7216293280626405 | loss: -111.459\n","Batch: 1 | Batch reward: 0.3365572006642725 | loss: 41.486\n","Batch: 2 | Batch reward: 0.7727077820314239 | loss: 107.033\n","Batch: 3 | Batch reward: -1.3621187060549262 | loss: -185.909\n","Batch: 4 | Batch reward: 0.6790041518960884 | loss: 112.547\n","Batch: 5 | Batch reward: 0.9393707184812498 | loss: 140.679\n","Batch: 6 | Batch reward: 0.3561081810445173 | loss: 53.353\n","Batch: 0 | Batch reward: -0.8351407385890615 | loss: -104.637\n","Batch: 1 | Batch reward: 0.5069730951753286 | loss: 47.101\n","Batch: 2 | Batch reward: 1.5958402704972556 | loss: 196.975\n","Batch: 3 | Batch reward: 1.5363799822562583 | loss: 121.576\n","Batch: 4 | Batch reward: 1.0773441520405642 | loss: 107.881\n","Batch: 5 | Batch reward: -3.3831096261359273 | loss: -222.932\n","Batch: 6 | Batch reward: -0.49828713524439094 | loss: -37.239\n","Batch: 0 | Batch reward: 0.6157963126828927 | loss: 52.726\n","Batch: 1 | Batch reward: 0.9408594849293201 | loss: 84.634\n","Batch: 2 | Batch reward: 1.114493906170926 | loss: 61.215\n","Batch: 3 | Batch reward: -1.2322665091745695 | loss: -74.542\n","Batch: 4 | Batch reward: 1.3357251393141734 | loss: 85.721\n","Batch: 5 | Batch reward: -2.3723432411895504 | loss: -151.731\n","Batch: 6 | Batch reward: -0.40226509273316124 | loss: -24.057\n","Batch: 0 | Batch reward: 1.089085320870453 | loss: 92.177\n","Batch: 1 | Batch reward: 1.1507688648058032 | loss: 77.197\n","Batch: 2 | Batch reward: 1.1546478109444802 | loss: 87.618\n","Batch: 3 | Batch reward: -0.9930843090563015 | loss: -56.053\n","Batch: 4 | Batch reward: 0.31025511816222195 | loss: 13.072\n","Batch: 5 | Batch reward: -1.762219068788575 | loss: -102.816\n","Batch: 6 | Batch reward: -0.949453736937967 | loss: -46.906\n","Batch: 0 | Batch reward: 1.1674288391720098 | loss: 64.305\n","Batch: 1 | Batch reward: -1.2847356395955782 | loss: -58.526\n","Batch: 2 | Batch reward: -1.2848250713332554 | loss: -84.147\n","Batch: 3 | Batch reward: -1.1492616714417185 | loss: -76.679\n","Batch: 4 | Batch reward: 0.7962114159441318 | loss: 52.683\n","Batch: 5 | Batch reward: 0.6063949467563818 | loss: 51.008\n","Batch: 6 | Batch reward: 1.1487871804979233 | loss: 96.362\n","Batch: 0 | Batch reward: 0.3021099947597893 | loss: 24.721\n","Batch: 1 | Batch reward: -0.7865991348976284 | loss: -57.064\n","Batch: 2 | Batch reward: 1.2106909803723616 | loss: 96.870\n","Batch: 3 | Batch reward: -0.8861835864950764 | loss: -63.491\n","Batch: 4 | Batch reward: -1.6774754230489117 | loss: -116.965\n","Batch: 5 | Batch reward: 1.2810294806619948 | loss: 79.500\n","Batch: 6 | Batch reward: 0.5564276886473769 | loss: 35.034\n","Batch: 0 | Batch reward: 0.7333824281065735 | loss: 64.302\n","Batch: 1 | Batch reward: -0.7382257995073428 | loss: -49.275\n","Batch: 2 | Batch reward: 0.16705085981147308 | loss: 14.512\n","Batch: 3 | Batch reward: 0.18685206208899502 | loss: 14.562\n","Batch: 4 | Batch reward: -1.7157541821092595 | loss: -121.443\n","Batch: 5 | Batch reward: -0.5840304952748147 | loss: -43.637\n","Batch: 6 | Batch reward: 1.9507251268843813 | loss: 155.644\n","Batch: 0 | Batch reward: -0.04757464043925082 | loss: -3.410\n","Batch: 1 | Batch reward: 0.396071287933215 | loss: 30.453\n","Batch: 2 | Batch reward: 1.482336253373241 | loss: 114.208\n","Batch: 3 | Batch reward: -0.591606726775364 | loss: -42.798\n","Batch: 4 | Batch reward: -1.8221055716200207 | loss: -158.642\n","Batch: 5 | Batch reward: -0.5570999649158521 | loss: -42.406\n","Batch: 6 | Batch reward: 1.1399793624439603 | loss: 77.857\n","Batch: 0 | Batch reward: 1.0218191544142297 | loss: 84.123\n","Batch: 1 | Batch reward: -0.7343680064278174 | loss: -54.653\n","Batch: 2 | Batch reward: -1.5604060937802386 | loss: -100.010\n","Batch: 3 | Batch reward: -1.2634782397476951 | loss: -82.002\n","Batch: 4 | Batch reward: 0.7076252614141655 | loss: 64.724\n","Batch: 5 | Batch reward: 1.1338240088407319 | loss: 85.700\n","Batch: 6 | Batch reward: 0.694983915286585 | loss: 47.339\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-16c398267022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mController\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_svc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Step1：训练svc class matching model（合并labeled dataset和pseudo_labeled_dataset）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mU_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mController\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_unlabeled_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mController\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlabeled_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mController\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-2df0b91e87cd>\u001b[0m in \u001b[0;36mtrain_svc_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_svc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mD_train_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeled_train_dataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpseudo_labeled_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeled_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpseudo_labeled_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_train_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MntMeatProducts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MntWines'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_train_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dependents_Flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_svc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"PT0YQxxBmmGS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XUDK51-El19g"}}]}